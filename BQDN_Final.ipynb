{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nu73hkdaEN5X",
        "outputId": "a443058f-d1e0-4880-aa0b-5637c965b383"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Round Robin Turnaround Times: [ 0.          4.91109149  7.68943365 10.26971244 26.1755574   0.\n",
            "  4.2998883   9.18228814 17.62279399 17.1511758   0.          5.03489941\n",
            " 11.03335495  7.56094029 19.54314934  0.          4.90240199  8.11998791\n",
            " 17.0424419  20.75178397  0.          4.19641779 10.25697216 17.07620962\n",
            " 16.38059296  0.          6.03649858  9.5873768  10.55666609 19.73934418\n",
            "  0.          5.21571323  9.9474069  16.83855839 25.49075949  0.\n",
            "  3.88664019  9.66506543 10.32707239 19.28122073  0.          5.67188334\n",
            " 11.22446498 16.61866951 18.72075322  0.          5.08760454  9.3381322\n",
            " 12.70178927 19.23595476  0.          3.50312119  9.31405682 13.61681503\n",
            " 22.74642542  0.          6.7799308   9.02213368 13.22170704 23.35412055\n",
            "  0.          6.63748199  9.83531651 15.53478035 24.58244264  0.\n",
            "  4.48033702 11.74939877 11.02520859 21.07400441  0.          5.46844797\n",
            " 14.0488165  15.73491769 29.32312554  0.          5.02374877 10.12651366\n",
            " 15.42438024 16.38272485  0.          5.34890873  8.35244017 10.66198057\n",
            " 18.91162613  0.          5.93502674  7.66444938 17.84633727 22.22303212\n",
            "  0.          5.52471766 11.01885988 12.76812483 19.50260457  0.\n",
            "  4.23111856 11.74934768 22.68854973 22.1188577 ]\n",
            "First Come First Serve Turnaround Times: [ 0.          4.91109149  7.68943365 10.26971244 26.1755574   0.\n",
            "  4.2998883   9.18228814 17.62279399 17.1511758   0.          5.03489941\n",
            " 11.03335495  7.56094029 19.54314934  0.          4.90240199  8.11998791\n",
            " 17.0424419  20.75178397  0.          4.19641779 10.25697216 17.07620962\n",
            " 16.38059296  0.          6.03649858  9.5873768  10.55666609 19.73934418\n",
            "  0.          5.21571323  9.9474069  16.83855839 25.49075949  0.\n",
            "  3.88664019  9.66506543 10.32707239 19.28122073  0.          5.67188334\n",
            " 11.22446498 16.61866951 18.72075322  0.          5.08760454  9.3381322\n",
            " 12.70178927 19.23595476  0.          3.50312119  9.31405682 13.61681503\n",
            " 22.74642542  0.          6.7799308   9.02213368 13.22170704 23.35412055\n",
            "  0.          6.63748199  9.83531651 15.53478035 24.58244264  0.\n",
            "  4.48033702 11.74939877 11.02520859 21.07400441  0.          5.46844797\n",
            " 14.0488165  15.73491769 29.32312554  0.          5.02374877 10.12651366\n",
            " 15.42438024 16.38272485  0.          5.34890873  8.35244017 10.66198057\n",
            " 18.91162613  0.          5.93502674  7.66444938 17.84633727 22.22303212\n",
            "  0.          5.52471766 11.01885988 12.76812483 19.50260457  0.\n",
            "  4.23111856 11.74934768 22.68854973 22.1188577 ]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/tensorflow_probability/python/layers/util.py:98: UserWarning: `layer.add_variable` is deprecated and will be removed in a future version. Please use the `layer.add_weight()` method instead.\n",
            "  loc = add_variable_fn(\n",
            "/usr/local/lib/python3.10/dist-packages/tensorflow_probability/python/layers/util.py:108: UserWarning: `layer.add_variable` is deprecated and will be removed in a future version. Please use the `layer.add_weight()` method instead.\n",
            "  untransformed_scale = add_variable_fn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4/4 [==============================] - 0s 5ms/step\n",
            "BDQN Agent Turnaround Times: [ 5.31281598  0.          0.          0.          6.54388935  8.96310205\n",
            "  8.59977659  9.18228814 11.74852933  8.5755879   7.30143046 15.10469824\n",
            " 11.03335495  5.04062686 14.657362    6.5621141   4.90240199  8.11998791\n",
            " 11.36162794 10.37589198 15.30148858  8.39283559 10.25697216 11.38413975\n",
            "  8.19029648 15.43698223 12.07299715 14.38106519  7.03777739  0.\n",
            "  0.         10.43142647 19.89481381  0.         12.74537975 20.59410128\n",
            "  0.         19.33013086  3.44235746  0.         21.20111158 11.34376669\n",
            " 11.22446498 22.15822601  0.         19.47830671  0.         18.67626441\n",
            "  4.23392976  9.61797738 10.19368899  3.50312119  9.31405682  4.53893834\n",
            " 22.74642542  5.93585399  0.         18.04426736  8.81447136  0.\n",
            "  4.19548065 13.27496397 19.67063302 10.35652024 12.29122132  6.8578963\n",
            "  8.96067403 11.74939877  7.35013906  5.2685011   0.         10.93689594\n",
            " 14.0488165  10.48994513  0.          0.         10.04749754 10.12651366\n",
            "  0.          0.          0.         10.69781747  8.35244017 14.21597409\n",
            " 18.91162613  3.67882672 17.80508021  7.66444938  0.         11.11151606\n",
            "  0.         11.04943532 22.03771976  8.51208322  9.75130228 22.52126757\n",
            "  0.         17.62402152  0.          0.        ]\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import tensorflow_probability as tfp\n",
        "tfd = tfp.distributions\n",
        "\n",
        "# Define custom prior layer\n",
        "class CustomPriorLayer(tfp.layers.DistributionLambda):\n",
        "    def __init__(self, event_size, dtype=tf.float32, **kwargs):\n",
        "        super(CustomPriorLayer, self).__init__(\n",
        "            make_distribution_fn=self.make_distribution_fn,\n",
        "            convert_to_tensor_fn=tfd.Distribution.sample,\n",
        "            dtype=dtype,\n",
        "            **kwargs\n",
        "        )\n",
        "        self.event_size = event_size\n",
        "\n",
        "    def make_distribution_fn(self, t):\n",
        "        return tfd.Normal(loc=t * 0.0, scale=1.0)  # Change the prior distribution as needed\n",
        "\n",
        "# Define Bayesian Q Network\n",
        "class BayesianQNetwork(tf.keras.Model):\n",
        "    def __init__(self, state_dim, action_dim):\n",
        "        super(BayesianQNetwork, self).__init__()\n",
        "        # Define Bayesian layers with specific priors\n",
        "        self.dense1 = tfp.layers.DenseFlipout(\n",
        "            128,\n",
        "            activation='relu',\n",
        "            kernel_posterior_fn=tfp.layers.default_mean_field_normal_fn(),\n",
        "            kernel_posterior_tensor_fn=lambda d: d.sample(),\n",
        "            kernel_divergence_fn=(lambda q, p, _: tfd.kl_divergence(q, p) / tf.cast(state_dim, dtype=tf.float32)),\n",
        "            bias_posterior_fn=tfp.layers.default_mean_field_normal_fn(),\n",
        "            bias_posterior_tensor_fn=lambda d: d.sample(),\n",
        "            bias_divergence_fn=(lambda q, p, _: tfd.kl_divergence(q, p) / tf.cast(state_dim, dtype=tf.float32)),\n",
        "        )\n",
        "        self.dense2 = tfp.layers.DenseFlipout(\n",
        "            action_dim,\n",
        "            activation=None,\n",
        "            kernel_posterior_fn=tfp.layers.default_mean_field_normal_fn(),\n",
        "            kernel_posterior_tensor_fn=lambda d: d.sample(),\n",
        "            kernel_divergence_fn=(lambda q, p, _: tfd.kl_divergence(q, p) / tf.cast(state_dim, dtype=tf.float32)),\n",
        "            bias_posterior_fn=tfp.layers.default_mean_field_normal_fn(),\n",
        "            bias_posterior_tensor_fn=lambda d: d.sample(),\n",
        "            bias_divergence_fn=(lambda q, p, _: tfd.kl_divergence(q, p) / tf.cast(state_dim, dtype=tf.float32)),\n",
        "        )\n",
        "\n",
        "    def call(self, state):\n",
        "        x = self.dense1(state)\n",
        "        q_values = self.dense2(x)\n",
        "        return q_values\n",
        "\n",
        "# Define BDQN\n",
        "class BayesianDQNAgent:\n",
        "    def __init__(self, state_dim, action_dim):\n",
        "        self.state_dim = state_dim\n",
        "        self.action_dim = action_dim\n",
        "        self.model = BayesianQNetwork(state_dim, action_dim)\n",
        "        self.optimizer = tf.keras.optimizers.Adam(learning_rate=1e-3)\n",
        "\n",
        "    def train_step(self, states, actions, rewards, next_states):\n",
        "        with tf.GradientTape() as tape:\n",
        "            # Compute Q values for the current and next states\n",
        "            q_values = self.model(states)\n",
        "            next_q_values = self.model(next_states)\n",
        "\n",
        "            # Use Huber loss for training\n",
        "            target_q_values = rewards + discount_factor * tf.reduce_max(next_q_values, axis=1)\n",
        "            action_masks = tf.one_hot(actions, self.action_dim)\n",
        "            selected_q_values = tf.reduce_sum(q_values * action_masks, axis=1)\n",
        "            loss = tf.reduce_mean(tf.losses.huber(target_q_values, selected_q_values))\n",
        "\n",
        "        gradients = tape.gradient(loss, self.model.trainable_variables)\n",
        "        self.optimizer.apply_gradients(zip(gradients, self.model.trainable_variables))\n",
        "\n",
        "    def train(self, num_episodes, batch_size):\n",
        "        for episode in range(num_episodes):\n",
        "            states, actions, rewards, next_states = generate_synthetic_data_with_turnaround_time(batch_size, self.state_dim, self.action_dim)\n",
        "            self.train_step(states, actions, rewards, next_states)\n",
        "\n",
        "# Generate synthetic dataset with turnaround time\n",
        "def generate_synthetic_data_with_turnaround_time(num_samples, state_dim, action_dim):\n",
        "    states = np.random.rand(num_samples, state_dim).astype(np.float32)\n",
        "    actions = np.random.randint(action_dim, size=num_samples)\n",
        "    next_states = np.random.rand(num_samples, state_dim).astype(np.float32)\n",
        "\n",
        "    # Compute turnaround time and use it to calculate rewards\n",
        "    turnaround_times = compute_turnaround_times(states, actions)\n",
        "    rewards = 1.0 / (turnaround_times+1e-6)  # Example: reward is inversely proportional to turnaround time\n",
        "\n",
        "    return states, actions, rewards, next_states\n",
        "\n",
        "# Compute turnaround times based on states and actions\n",
        "def compute_turnaround_times(states, actions):\n",
        "    if len(actions.shape) == 1:\n",
        "        # If actions is 1D, convert it to a 2D array with a single column\n",
        "        actions = actions[:, np.newaxis]\n",
        "\n",
        "    turnaround_times = np.sum(states * actions, axis=1)\n",
        "    return turnaround_times\n",
        "\n",
        "\n",
        "# Round Robin Scheduling\n",
        "def round_robin_scheduling(states, action_dim):\n",
        "    num_samples = states.shape[0]\n",
        "    actions = np.tile(np.arange(action_dim), num_samples // action_dim)[:, np.newaxis]\n",
        "    return actions\n",
        "\n",
        "# First Come First Serve Scheduling\n",
        "def first_come_first_serve_scheduling(states, action_dim):\n",
        "    num_samples = states.shape[0]\n",
        "    actions = np.arange(num_samples)[:, np.newaxis] % action_dim\n",
        "    return actions\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Comparison function\n",
        "def compare_algorithms(state_dim, action_dim, num_samples):\n",
        "    # Generate synthetic data\n",
        "    states, _, _, _ = generate_synthetic_data_with_turnaround_time(num_samples, state_dim, action_dim)\n",
        "\n",
        "    # Round Robin Scheduling\n",
        "    rr_actions = round_robin_scheduling(states, action_dim)\n",
        "    rr_turnaround_times = compute_turnaround_times(states, rr_actions)\n",
        "    print(\"Round Robin Turnaround Times:\", rr_turnaround_times)\n",
        "\n",
        "    # First Come First Serve Scheduling\n",
        "    fcfs_actions = first_come_first_serve_scheduling(states, action_dim)\n",
        "    fcfs_turnaround_times = compute_turnaround_times(states, fcfs_actions)\n",
        "    print(\"First Come First Serve Turnaround Times:\", fcfs_turnaround_times)\n",
        "\n",
        "    # Bayesian Deep Q Network (BDQN) Agent\n",
        "    agent = BayesianDQNAgent(state_dim, action_dim)\n",
        "    agent.train(num_episodes=100, batch_size=32)  # Train the agent\n",
        "    bdqn_actions = np.argmax(agent.model.predict(states), axis=1)\n",
        "    bdqn_turnaround_times = compute_turnaround_times(states, bdqn_actions)\n",
        "    print(\"BDQN Agent Turnaround Times:\", bdqn_turnaround_times)\n",
        "\n",
        "# Hyperparameters\n",
        "state_dim = 10\n",
        "action_dim = 5\n",
        "discount_factor = 0.99\n",
        "num_samples = 100\n",
        "\n",
        "# Compare algorithms\n",
        "compare_algorithms(state_dim, action_dim, num_samples)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "W-uMjSdtEQ6L"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}